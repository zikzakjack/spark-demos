{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark - A Unified engine for large-scale data analytics\n",
    "\n",
    "Apache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tool\n",
    "s including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrames\n",
    "\n",
    "A DataFrame is conceptually equivalent to a table in a relational database or a data frame in R/Python, but with richer optimizations under the hood. DataFrames can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing RDDs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# findspark\n",
    "\n",
    "- findspark is a Python library that helps you configure your Python environment to use PySpark. \n",
    "- It automatically sets the necessary environment variables like SPARK_HOME and JAVA_HOME, which are crucial for PySpark to locate the Spark installation and Java runtime. \n",
    "- It acts as a bridge between your Python environment and the Apache Spark installation, making it a convenient tool for working with PySpark in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in .\\.venv\\lib\\site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Point: SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"ZikSpark\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisite: 2023 Yellow Taxi Trip Data\n",
    "\n",
    "[Yellow Taxi](data/yellow-taxi) is a large dataset that can be used to effectively demonstrate various Spark features. It is 3.51 GB with 38310226 rows. Data file cannot be version controlled in Github due to siz limitations. As a pre-requisite, the dataset should be downloaded and placed locally. Refer the [README](data/yellow-taxi/README.md) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       2|01/01/2023 12:32:...| 01/01/2023 12:40:...|              1|         0.97|         1|                 N|         161|         141|           2|        9.3|  1.0|    0.5|       0.0|         0.0|                  1.0|        14.3|                 2.5|        0.0|\n",
      "|       2|01/01/2023 12:55:...| 01/01/2023 01:01:...|              1|          1.1|         1|                 N|          43|         237|           1|        7.9|  1.0|    0.5|       4.0|         0.0|                  1.0|        16.9|                 2.5|        0.0|\n",
      "|       2|01/01/2023 12:25:...| 01/01/2023 12:37:...|              1|         2.51|         1|                 N|          48|         238|           1|       14.9|  1.0|    0.5|      15.0|         0.0|                  1.0|        34.9|                 2.5|        0.0|\n",
      "|       1|01/01/2023 12:03:...| 01/01/2023 12:13:...|              0|          1.9|         1|                 N|         138|           7|           1|       12.1| 7.25|    0.5|       0.0|         0.0|                  1.0|       20.85|                 0.0|       1.25|\n",
      "|       2|01/01/2023 12:10:...| 01/01/2023 12:21:...|              1|         1.43|         1|                 N|         107|          79|           1|       11.4|  1.0|    0.5|      3.28|         0.0|                  1.0|       19.68|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawdata_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"data\\\\yellow-taxi\\\\2023_Yellow_Taxi_Trip_Data_20240909.csv\")\n",
    "\n",
    "rawdata_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
